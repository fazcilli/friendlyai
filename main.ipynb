{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (30162, 15)\n",
      "Test (15060, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "def read_clean_data():\n",
    "    train = pd.read_csv('./data/adult.data', index_col=None, header=None)\n",
    "    test = pd.read_csv('./data/adult.test', index_col=None, header=None)\n",
    "    columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "               'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "               'income']\n",
    "    train.columns = columns\n",
    "    test.columns = columns\n",
    "    # drop rows with nan values\n",
    "    train.replace({' ?': np.nan}, inplace=True)\n",
    "    train.dropna(inplace=True)\n",
    "    train.head()\n",
    "    test.replace({' ?': np.nan}, inplace=True)\n",
    "    test.dropna(inplace=True)\n",
    "\n",
    "    # clean target strings from test set\n",
    "    test.replace({\n",
    "        ' <=50K.': ' <=50K',\n",
    "        ' >50K.': ' >50K'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # save cleaned versions\n",
    "    train.to_csv('./data/cleaned_train.csv')\n",
    "    test.to_csv('./data/cleaned_test.csv')\n",
    "\n",
    "\n",
    "train = pd.read_csv('./data/cleaned_train.csv', index_col=0)\n",
    "test = pd.read_csv('./data/cleaned_test.csv', index_col=0)\n",
    "print('Train', train.shape)\n",
    "print('Test', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass: 7 values\n",
      "[' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov'\n",
      " ' Self-emp-inc' ' Without-pay'] \n",
      "\n",
      "education: 16 values\n",
      "[' Bachelors' ' HS-grad' ' 11th' ' Masters' ' 9th' ' Some-college'\n",
      " ' Assoc-acdm' ' 7th-8th' ' Doctorate' ' Assoc-voc' ' Prof-school'\n",
      " ' 5th-6th' ' 10th' ' Preschool' ' 12th' ' 1st-4th'] \n",
      "\n",
      "marital-status: 7 values\n",
      "[' Never-married' ' Married-civ-spouse' ' Divorced'\n",
      " ' Married-spouse-absent' ' Separated' ' Married-AF-spouse' ' Widowed'] \n",
      "\n",
      "occupation: 14 values\n",
      "[' Adm-clerical' ' Exec-managerial' ' Handlers-cleaners' ' Prof-specialty'\n",
      " ' Other-service' ' Sales' ' Transport-moving' ' Farming-fishing'\n",
      " ' Machine-op-inspct' ' Tech-support' ' Craft-repair' ' Protective-serv'\n",
      " ' Armed-Forces' ' Priv-house-serv'] \n",
      "\n",
      "relationship: 6 values\n",
      "[' Not-in-family' ' Husband' ' Wife' ' Own-child' ' Unmarried'\n",
      " ' Other-relative'] \n",
      "\n",
      "race: 5 values\n",
      "[' White' ' Black' ' Asian-Pac-Islander' ' Amer-Indian-Eskimo' ' Other'] \n",
      "\n",
      "sex: 2 values\n",
      "[' Male' ' Female'] \n",
      "\n",
      "native-country: 41 values\n",
      "[' United-States' ' Cuba' ' Jamaica' ' India' ' Mexico' ' Puerto-Rico'\n",
      " ' Honduras' ' England' ' Canada' ' Germany' ' Iran' ' Philippines'\n",
      " ' Poland' ' Columbia' ' Cambodia' ' Thailand' ' Ecuador' ' Laos'\n",
      " ' Taiwan' ' Haiti' ' Portugal' ' Dominican-Republic' ' El-Salvador'\n",
      " ' France' ' Guatemala' ' Italy' ' China' ' South' ' Japan' ' Yugoslavia'\n",
      " ' Peru' ' Outlying-US(Guam-USVI-etc)' ' Scotland' ' Trinadad&Tobago'\n",
      " ' Greece' ' Nicaragua' ' Vietnam' ' Hong' ' Ireland' ' Hungary'\n",
      " ' Holand-Netherlands'] \n",
      "\n",
      "income: 2 values\n",
      "[' <=50K' ' >50K'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# categorical variables number of unique values\n",
    "for c in train.columns:\n",
    "    if train[c].dtype != 'object':\n",
    "        continue\n",
    "    vals = train[c].unique()\n",
    "    print('%s: %d values' % (c, len(vals)))\n",
    "    print(vals, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "lenc = LabelEncoder()\n",
    "\n",
    "y_train = pd.DataFrame(lenc.fit_transform(train['income']))\n",
    "y_test = pd.DataFrame(lenc.transform(test['income']))\n",
    "y_train.index = train.index\n",
    "y_test.index = test.index\n",
    "X_train = train.drop(['income'], axis=1)\n",
    "X_test = test.drop(['income'], axis=1)\n",
    "\n",
    "numeric_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']]\n",
    "obj_cols = [cname for cname in X_train.columns if X_train[cname].dtype == 'object']\n",
    "oh_cols = pd.DataFrame(enc.fit_transform(X_train[obj_cols]))\n",
    "oh_cols_test = pd.DataFrame(enc.transform(X_test[obj_cols]))\n",
    "oh_cols.index = X_train.index\n",
    "oh_cols_test.index = X_test.index\n",
    "X_train = pd.concat([X_train.drop(obj_cols, axis=1), oh_cols], axis=1)\n",
    "X_test = pd.concat([X_test.drop(obj_cols, axis=1), oh_cols_test], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf = LogisticRegressionCV(cv=5, random_state=0, Cs=10).fit(X_train, y_train)\n",
    "print('Training score:', clf.score(X_train, y_train))\n",
    "print('Test score:', clf.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Income': ['<=50K', '>50K'],\n",
    "    'Training': list(train['income'].value_counts()),\n",
    "    'Test': list(test['income'].value_counts())\n",
    "})\n",
    "fig, ax = plt.subplots(1)\n",
    "df.plot(x='Income', y=['Training', 'Test'], kind='bar', ax=ax)\n",
    "plt.xticks(rotation=0)\n",
    "fig.savefig('./output/class-dist.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9999336913997745\n",
      "Test score: 0.8461487383798141\n"
     ]
    }
   ],
   "source": [
    "def row_to_dict(X, y=None):\n",
    "    return X.apply(dict, axis=1)\n",
    "\n",
    "\n",
    "# define prediction model\n",
    "ft = FunctionTransformer(row_to_dict, validate=False)\n",
    "dv = DictVectorizer()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# glue steps together\n",
    "model = make_pipeline(ft, dv, rf)\n",
    "y = train['income']\n",
    "model.fit(train.drop(['income'], axis=1), y)\n",
    "print('Training score:', model.score(train.drop(['income'], axis=1), train['income']))\n",
    "print('Test score:', model.score(test.drop(['income'], axis=1), test['income']))\n",
    "\n",
    "# get feature importances\n",
    "feature_importances = list(zip(dv.feature_names_, rf.feature_importances_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# aggregate categorical variables' importance\n",
    "res = dict()\n",
    "for x in feature_importances:\n",
    "    n, v = x\n",
    "    ind = n.find('=')\n",
    "    if ind > -1:\n",
    "        n2 = n[:ind]\n",
    "        if n2 in res:\n",
    "            res[n2] += v\n",
    "        else:\n",
    "            res[n2] = v\n",
    "    else:\n",
    "        res[n] = v\n",
    "# plot feature importance\n",
    "keyys = res.keys()\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.bar(keyys, [res[x] for x in keyys])\n",
    "plt.xticks(rotation=90)\n",
    "fig.savefig('./output/weights.png')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}